---
title: "Causal inference and experimental methods"
author: "Macartan Humphreys"
numbersections: true
header-includes:
  - \usepackage{amsmath, amssymb, bbm, amstext, array, listings, mathtools, multicolumn, caption, color, graphics, ulem, caption, changepage, atbegshi, soul, xcolor}
  - \newcommand\E{\mathbb{E}}
  - \newcommand\V{\mathbb{V}}
  - \hypersetup{colorlinks=true,linkcolor=red}
  - \usepackage{ulem}
  - \pdfstringdefDisableCommands{\let\sout\relax}
fontsize: 11pt  
output:
  beamer_presentation:
    slide_level: 2
    keep_tex: false
    includes:
      in_header: include_nav.txt
  ioslides_presentation:
    self_contained: yes
    widescreen: no
---


## Take home ideas

1. A causal claim is a claim about what **did not happen**

2. You have to have an **estimand**. You should be able to describe this in terms of **potential outcomes**.


## Motivation 

The \textit{intervention} based motivation for understanding causal effects:
\begin{itemize}
	\item  We want to know if a particular  intervention (like aid) caused a particular outcome (like reduced corruption). 
	\item  We need to know:
\begin{enumerate}
	\item What happened?
	\item What would the outcome have been if there were no intervention?
\end{enumerate}

	\item  The problem
\begin{enumerate}
	\item \dots this is hard
	\item \dots this is impossible
\end{enumerate}

The problem in 2 is that you need to know what would have happened if things were different. You need information on a \textbf{counterfactual}
\end{itemize}


## Notation

We will use:

* $Y$ to denote an outcome (the dependent variable, the left hand side variables, the endogenous variables)

* $X$ (or sometimes, $Z$) to denote a  cause (the independent variable, the driver, the right hand side variables, the exogenous variables)
  * $X_1, X_2, \dots$ for particular causes

Different research projects:

 * $? \rightarrow Y$: What causes $Y$?
 * $X \rightarrow ?$: What does  $X$ do?
 * $X \rightarrow Y ?$: Does  $X$ cause $Y$?
 * $? \rightarrow ? ?$: What's up?
 
Know your $X$ and your $Y$.

## Potential Outcomes: Simple case

\begin{itemize}
	\item For each unit we assume that there are two \textbf{post-treatment} outcomes: $Y_i(1)$ and $Y_i(0)$. 
\begin{itemize}
	\item $Y(0)$ is the outcome that \textbf{would} obtain \textit{if} the unit did not receive the treatment
	\item $Y(1)$ is the outcome that \textbf{would} obtain \textit{if} the unit received the treatment
\end{itemize}
	\item  The \textbf{causal effect }of Treatment (relative to Control) is:
	$$ \tau_i = Y_i(1) - Y_i(0)$$
	\item Note: 
	
\begin{itemize}
	\item the causal effect is defined at the \textit{individual level}. 
	\item there is no ``data generating process'' or functional form 
	\item the causal effect is defined relative to something else  (did Germany cause the second world war?)
\end{itemize}
\end{itemize}


## Causal claims: What is  seen?

\begin{itemize}
	\item We have talked about what's potential, now what {do} we \textit{observe}? 
	\item Say $X_i$ indicates whether the unit $i$ is assigned to treatment $(X_i=1)$ or not $(X_i=0)$. Then what we observe is:
	$$ Y_i = X_iY_i(1) + (1-X_i)Y_i(0) $$

\item Say $X$ is a random variable, then this is a sort of data generating process. BUT the key things to note is	
\begin{itemize}
	\item 	$Y_i$ is random but the randomness comes from $X_i$ --- the potential outcomes, $Y_i(1)$, $Y_i(0)$ are fixed 

\end{itemize}
\end{itemize}

<!-- Looks nothing like regression -->

## Five implications of the counterfactual definition

## 1. Causal statements are partly about what did not happen

**Inference**: We define causes in terms of things that did not happen. This puts **inference** front and center.

* Assessing effects is not a measurement problem, it is an inference problem. This is true whether we use quantitative or qualitative methods. 

<!-- ## 1. Causal statements are partly about what did not happen -->

<!-- Compare this to a **structural approach**. In a structural approach we assume a data generating process in which outcome $Y$ is a function of $X$.  -->
<!-- $$y = f_Y(x, u_Y), u_Y\sim p_Y$$ -->

<!-- Compared to: -->
<!-- 	$$ Y_i = Z_iY_i(1) + (1-Z_i)Y_i(0) $$ -->

<!-- * Here knowing the effect of $X$ on $Y$ means knowing the functional form $f_Y$ and knowing background conditions, $u_Y$. -->
<!-- * It does not require forming beliefs about what did not happen (the counterfactual claims are now buried inside $f_Y$) -->

<!-- ## Compare with structural approach -->

<!-- **Illustration**:  Say that cellphones turn on if and only if they are **intact** and have a **charged battery**.  -->

<!-- *Question*: Does providing a charged battery cause cellphones to turn on? -->

<!-- * In the **potential outcomes** framework this requires making guesses from the data about how cellphones work with and without batteries. It is not a measure problem, but an *inference* problem. -->
<!-- * For the **structural approach** this figuring out whether cellphones are intact. It is *measurement* problem (conditional on the model). -->


## 2. Causal relations are not transitive


\begin{itemize}
		\item If for a given unit $A$ causes $B$ and $B$ causes $C$, does that mean that $A$ causes $C$? 
		
		\color{red}\small A boulder is flying down a mountain. You duck. This saves your life.  
			
			So the boulder caused the ducking and the ducking caused you to survive. So: \textit{did the boulder cause you to survive?} 
		\color{black}

\end{itemize}

*What implications of non-transitivity?*


## 3: Causal paths are not spatially connected 



Say $A$ causes $B$ --- does that mean that there is a spatiotemporally continuous sequence of causal intermediates? 
		

* Person $A$ is planning some action $Y$
* Person $B$ sets out to stop them
* Person $X$ intervenes and prevents $B$ from stopping person $A$
		
In this case Person $A$ may complete their action, producing $Y$, without any knowledge that $B$ and $X$ even exist; in particular $X$ need not be anywhere close to the action. 

But still, $X$ caused $Y$ 

*What implications of non-connectedness?*



## 4: Causes are not rival 

The counterfactual model focuses on contribution, not attribution, except in a very conditional sense. 

* Focus is on  **non-rival** contributions. Not: what caused $Y$ but **what is the effect of $X$**? 
* At most it provides a conditional account of what caused $Y$---whether a particular thing caused $Y$, given other things.

Consider at outcome $Y$ that might depend on two causes $X_1$ and $X_2$:
$$Y(0,0) = 0$$
$$Y(1,0) = 0$$
$$Y(0,1) = 0$$
$$Y(1,1) = 1$$

What caused $Y$? Which cause was most important?


## 4: Causes are not rival 

The counterfactual model focuses on contribution, not attribution, except in a very conditional sense. 

* Focus is on  **non-rival** contributions. Not: what caused $Y$ but **what is the effect of $X$**? 
* At most it provides a conditional account of what caused $Y$---whether a particular thing caused $Y$, given other things.

Consider at outcome $Y$ that might depend on two causes $X_1$ and $X_2$:
$$Y(0,0) = 0$$
$$Y(1,0) = 1$$
$$Y(0,1) = 1$$
$$Y(1,1) = 1$$

What caused $Y$? Which cause was most important?


## 4: Causes are not rival 

The counterfactual model focuses on contribution, not attribution, except in a very conditional sense. 

* This is problem for research programs that define "explanation" in terms of figuring out the things that cause Y
* Real difficulties conceptualizing what it means to say one cause is more important than another cause. What does that mean?

<!-- ## 4: Causes are not rival  -->

<!-- The counterfactual model focuses on contribution, not attribution, except in a very conditional sense.  -->


<!-- * *Erdogan's increasing authoritarianism was the most important reason for the attempted coup* -->
<!--     * More important than Turkey's history of coups? -->
<!--     * What does that mean? -->


<!-- ## The difference between an *actual* cause a *counterfactual* cause -->

<!-- * Susie and Billy throw rocks at a bottle -->
<!-- * Both are great aims and, if they were the only ones throwing, would certainly hit the bottl.e -->
<!-- * Susie is a faster throw however and her rock hits the bottle first. -->
<!-- * Billy's throw is a little slower and flys past the now broken bottle. -->

<!-- **Question**: Which stone broke the bottle? -->


<!-- ## The difference between an *actual* cause and a *counterfactual* cause -->

<!-- * Susie and Billy throw rocks at a bottle -->
<!-- * Both are great aims and, if they were the only ones throwing, would certainly hit the bottl.e -->
<!-- * Susie is a faster throw however and her rock hits the bottle first. -->
<!-- * Billy's throw is a little slower and flys past the now broken bottle. -->

<!-- **Question**: From a counterfactual perspective *neither* broke the bottle since the bottle would have broken in the absence of any single throw. Yet it seems obvious that Susie's throw actually broke the bottle. (To think about: what does "actually" caused actually mean?)  -->



## 5: No causation without manipulation

* Some seemingly causal claims not admissible. 
* To get the definition off the ground, **manipulation must be imaginable** (whether practical or not)
* This renders thinking about effects of race and gender difficult
* What does it mean to say that Aunt Pat voted for Brexit because she is old?


## 5: No causation without manipulation

* Some seemingly causal claims not admissible. 
* To get the definition off the ground, **manipulation must be imaginable** (whether practical or not)
* This renders thinking about effects of race and gender difficult
* **Compare**: What does it mean to say that Southern counties voted for Brexit because they have many old people?


<!-- ## Causal claims: Causal claims are everywhere -->

<!-- Which of these statements involve causal claims: -->

<!-- * Jack exploited Jill -->
<!-- * It's Jill's fault that bucket fell -->
<!-- * Jack is the most obstructionist member of Congress -->
<!-- * Melania Trump stole from Michelle Obama's speech -->

<!-- So: -->

<!-- * Policymakers and activists need causal claims -->



## Exercise your potential outcomes 1

Consider the following potential outcomes table:

\begin{table} \centering
\begin{tabular}{c|c|c|c}
Unit	&Y(0)	&Y(1)	&$\tau_i$ \\ \hline
1	& 4	& 3	\\
2	& 2	& 3	\\
3	& 1	& 3	\\
4	& 1	& 3	\\
5	& 2	& 3	
\end{tabular} 
\end{table}

\color{red}\textbf{Questions for us:} What are the unit level treatment effects? What is the average treatment effect?	


## Exercise your potential outcomes 2
Consider the following potential outcomes table:
\begin{table} \centering

	\begin{tabular}{c|c|c}
		In treatment?	&Y(0)	&Y(1)  \\ \hline
		Yes	&	& 2	\\
		No	& 3	&	\\
		No	& 1	&	\\
		Yes	&	& 3	\\
		Yes	&	& 3	\\
		No	& 2	&	
	\end{tabular} 
\end{table}

\color{red}\textbf{Questions for us: } Fill in the blanks.
\begin{itemize}
	\item Assuming a constant treatment effect of $+1$ 
	\item Assuming a constant treatment effect of $-1$ 
	\item Assuming an \textit{average} treatment effect of $0$
\end{itemize}
\color{red} What is the actual treatment effect?


## Estimands

* The estimand is the thing you want to estimate
* If you are estimating something you should be able to say what your estimand is
* You are responsible for your estimand. Your estimator will not tell you what your estimand is
* Just because you can calculate something does not mean that you have an estimand (You can test a hypothesis without having an estimand)

<!-- ## Estimands: The Average Treatment Effect -->

<!-- * The most common estimand is the **average treatment effect** -->

<!-- * This is a **summary** of individual treatment effects: -->
<!-- $$\tau_i = Y_i(1) - Y_i(0)$$  -->

<!-- * For persons 1 and 2, the average is: -->
<!-- $$\tau = \frac{1}{2}(Y_1(1) - Y_1(0)) + \frac{1}{2}(Y_2(1) - Y_2(0))$$  -->

<!-- * More generally: -->
<!-- $$\tau = \sum_i\frac{1}{n}(Y_i(1) - Y_i(0))$$  -->

<!-- ## Estimands: ATE, ATT, ATC, S-, P-, C-, ITT, LATE -->
<!-- Say that units are randomly assigned to treatment in different strata (maybe just one); with fixed, though possibly different, shares assigned in each stratum. Then the key estimands and estimators are: -->
<!-- \scriptsize -->
<!-- \begin{table}[htbp] \scriptsize -->
<!-- 	\centering -->
<!-- 		\begin{tabular}{rlclrl} \scriptsize  -->
<!-- $\label{ATE} \tau_{ATE} \equiv$&$E\left(\tau_i\right) $&$=$&$ \sum\nolimits_{x} \frac{w_x}{\sum\nolimits_{j}w_{j}}\tau_x  $&$ \widehat{\tau}_{ATE} =$&$\sum\nolimits_{x} \frac{w_x}{\sum\nolimits_{j}w_{j}}\widehat{\tau}_x$ \\ -->
<!-- $\label{ATT} \tau_{ATT} \equiv$&$E\left(\tau_i\right | Z_i = 1) $&=&$\sum\nolimits_{x} \frac{p_xw_x}{\sum\nolimits_{j}p_jw_j}\tau_x  $&$  \widehat{\tau}_{ATT} =$&$\sum\nolimits_{x} \frac{p_xw_x}{\sum\nolimits_{j}p_jw_j}\widehat{\tau}_x$ \\ -->
<!-- $\label{ATC} \tau_{ATC} \equiv$&$E\left(\tau_i\right |  Z_i = 0) $&=&$\sum\nolimits_{x} \frac{(1-p_x)w_x}{\sum\nolimits_{j}(1-p_j)w_j}\tau_x  $&$ \widehat{\tau}_{ATC} =$&$\sum\nolimits_{x} \frac{(1-p_x)w_x}{\sum\nolimits_{j}(1-p_j)w_j}\widehat{\tau}_x $ -->
<!-- 		\end{tabular} -->
<!-- \end{table} -->
<!-- where $x$ indexes strata, $p_x$ is the share of units in each stratum that is treated, and $w_x$ is the size of a stratum. -->

<!-- Here: -->
<!-- \begin{itemize} -->
<!-- 	\item ATE is Average Treatment Effect (all units) -->
<!-- 	\item ATT is Average Treatment Effect on the Treated -->
<!-- 	\item ATC is Average Treatment Effect on the Controls -->
<!-- 	\end{itemize} -->



<!-- ## Estimands: ATE, ATT, ATC, S-, P-, C-, ITT, LATE -->
<!-- \footnotesize -->
<!-- In addition, each of these can be targets of interest: -->
<!-- \begin{itemize}  -->
<!-- 	\item for the \textbf{population}, in which case we refer to PATE, PATT, PATC and $\widehat{PATE}, \widehat{PATT},  \widehat{PATC}$ -->
<!-- 	\item for a \textbf{sample}, in which case we refer to SATE, SATT, SATC, and $\widehat{SATE}, \widehat{SATT},  \widehat{SATC}$ -->
<!-- \end{itemize} -->
<!-- And for different subgroups,  -->
<!-- \begin{itemize}  -->
<!-- 	\item given some value on a covariate, in which case we refer to CATE (conditional average treatment effect) -->
<!-- 	\item for unobservable subgroups, we estimate LATE (Local Average Treatment Effect (see below). -->
<!-- \end{itemize} -->
<!-- With non-compliance we might estimate ITT ---the ``intention to treat'' effect -->

<!-- \bigskip -->
<!-- Skip to \hyperlink{Fixer}{\beamergotobutton{Fixer}}  or \hyperlink{nools}{\beamergotobutton{Inference 1}} or \hyperlink{ideas}{\beamerreturnbutton{Big Ideas}}  -->



## Examples of estimands

* The average effect in the population
* The average effect in the sample
* The average effect for those treated
* The average (counterfactual) effect for those not treated
* The effect of assigning treatment
* The effect of receiving treatment
* The effect for men, for women
* The effect of one effect on another effect
* Whether $X=1$ was the cause of $Y = 1$
* More difficult: the share of the effect of $X$ on $Y$ that passes through mediator $M$


## Examples of estimands

Consider the factorial design:

<!-- \begin{table} -->
<!-- \begin{tabular}{c c|c c} -->
<!-- 	\hline  -->
<!-- 	&  & X2 & \\  -->
<!-- 	&  & 0 & 1  \\  -->
<!-- 	\hline  -->
<!-- X1	&  0 & & \\  -->
<!--     &  1 & &	\hline  -->
<!-- \end{tabular}  -->
<!-- \end{table} -->



\begin{table}
\centering
\begin{tabular}{cc|ccc}\scriptsize
& & X2 \\
& & 0 & 1\\  \hline
X1 & 0 & Y(0,0) & Y(0,1)\\ 
 & 1 & Y(1,0) & Y(1,1)\\
\end{tabular}  
\end{table}




Multiple targets of inference in a \color{red}factorial design

* **Interactive** effect is $$(Y(1,1) - Y(0,1)) - (Y(1, 0) - Y(0,0))$$
* **Interpretation**: How much bigger is the effect of $X1$ when $X2=1$ than it is when $X2=0$




## Examples of estimands

Consider the factorial design:

<!-- \begin{table} -->
<!-- \begin{tabular}{c c|c c} -->
<!-- 	\hline  -->
<!-- 	&  & X2 & \\  -->
<!-- 	&  & 0 & 1  \\  -->
<!-- 	\hline  -->
<!-- X1	&  0 & & \\  -->
<!--     &  1 & &	\hline  -->
<!-- \end{tabular}  -->
<!-- \end{table} -->



\begin{table}
\centering
\begin{tabular}{cc|ccc}\scriptsize
& & X2 \\
& & 0 & 1\\  \hline
X1 & 0 & Y(0,0) & Y(0,1)\\ 
 & 1 & Y(1,0) & Y(1,1)\\
\end{tabular}  
\end{table}


**Question**: What is the estimand "\color{red}The overall effect of X1\color{black}"?


## Takeaway on Estimands

* \color{red}Takeaway\color{black}: Estimands (the target of inference) should be definable in terms of potential outcomes. Model not generally required for defining the estimand. 

