---
title: "Causal inference and experimental methods"
author: "Macartan Humphreys"
numbersections: true
header-includes:
  - \usepackage{amsmath, amssymb, bbm, amstext, array, listings, mathtools, multicolumn, caption, color, graphics, ulem, caption, changepage, atbegshi, soul, xcolor}
  - \newcommand\E{\mathbb{E}}
  - \newcommand\V{\mathbb{V}}
  - \hypersetup{colorlinks=true,linkcolor=red}
  - \usepackage{ulem}
  - \pdfstringdefDisableCommands{\let\sout\relax}
fontsize: 11pt  
output:
  beamer_presentation:
    slide_level: 2
    keep_tex: false
    includes:
      in_header: include_nav.txt
  ioslides_presentation:
    self_contained: yes
    widescreen: no
---



## Motivation 

The \textit{intervention} based motivation for understanding causal effects:
\begin{itemize}
	\item  We want to know if a particular  intervention (like aid) caused a particular outcome (like reduced corruption). 
	\item  We need to know:
\begin{enumerate}
	\item What happened?
	\item What would the outcome have been if there were no intervention?
\end{enumerate}

	\item  The problem
\begin{enumerate}
	\item \dots this is hard
	\item \dots this is impossible
\end{enumerate}

The problem in 2 is that you need to know what would have happened if things were different. You need information on a \textbf{counterfactual}
\end{itemize}


## Potential Outcomes: Simple case

\begin{itemize}
	\item For each unit we assume that there are two \textbf{post-treatment} outcomes: $Y_i(1)$ and $Y_i(0)$. 
\begin{itemize}
	\item $Y(0)$ is the outcome that \textbf{would} obtain \textit{if} the unit did not receive the treatment
	\item $Y(1)$ is the outcome that \textbf{would} obtain \textit{if} the unit received the treatment
\end{itemize}
	\item  The \textbf{causal effect }of Treatment (relative to Control) is:
	$$ \tau_i = Y_i(1) - Y_i(0)$$
	\item Note: 
	
\begin{itemize}
	\item the causal effect is defined at the \textit{individual level}. 
	\item there is no ``data generating process'' or functional form 
	\item the causal effect is defined relative to something else  (did Germany cause the second world war?)
\end{itemize}
\end{itemize}


## Causal claims: What is  seen?

\begin{itemize}
	\item We have talked about what's potential, now what {do} we \textit{observe}? 
	\item Say $X_i$ indicates whether the unit $i$ is assigned to treatment $(X_i=1)$ or not $(X_i=0)$. Then what we observe is:
	$$ Y_i = X_iY_i(1) + (1-X_i)Y_i(0) $$

\item Say $X$ is a random variable, then this is a sort of data generating process. BUT the key things to note is	
\begin{itemize}
	\item 	$Y_i$ is random but the randomness comes from $X_i$ --- the potential outcomes, $Y_i(1)$, $Y_i(0)$ are fixed 

\end{itemize}
\end{itemize}

<!-- Looks nothing like regression -->

## Implications

Five implications of the counterfactual definition:


1. You *infer* causation you don't observe of measure causes
2. Causal relations are not transitive
3. Causal paths are not spatially connected 
4. Causes are not rival 
5. No causation without manipulation














## 1. Causal statements are partly about what did not happen

**Inference**: We define causes in terms of things that did not happen. This puts **inference** front and center.

* Assessing effects is not a measurement problem, it is an inference problem. This is true whether we use quantitative or qualitative methods. 

<!-- ## 1. Causal statements are partly about what did not happen -->

<!-- Compare this to a **structural approach**. In a structural approach we assume a data generating process in which outcome $Y$ is a function of $X$.  -->
<!-- $$y = f_Y(x, u_Y), u_Y\sim p_Y$$ -->

<!-- Compared to: -->
<!-- 	$$ Y_i = Z_iY_i(1) + (1-Z_i)Y_i(0) $$ -->

<!-- * Here knowing the effect of $X$ on $Y$ means knowing the functional form $f_Y$ and knowing background conditions, $u_Y$. -->
<!-- * It does not require forming beliefs about what did not happen (the counterfactual claims are now buried inside $f_Y$) -->

<!-- ## Compare with structural approach -->

<!-- **Illustration**:  Say that cellphones turn on if and only if they are **intact** and have a **charged battery**.  -->

<!-- *Question*: Does providing a charged battery cause cellphones to turn on? -->

<!-- * In the **potential outcomes** framework this requires making guesses from the data about how cellphones work with and without batteries. It is not a measure problem, but an *inference* problem. -->
<!-- * For the **structural approach** this figuring out whether cellphones are intact. It is *measurement* problem (conditional on the model). -->


## 2. Causal relations are not transitive


\begin{itemize}
		\item If for a given unit $A$ causes $B$ and $B$ causes $C$, does that mean that $A$ causes $C$? 
		
		\color{red}\small A boulder is flying down a mountain. You duck. This saves your life.  
			
			So the boulder caused the ducking and the ducking caused you to survive. So: \textit{did the boulder cause you to survive?} 
		\color{black}

\end{itemize}

*What implications of non-transitivity?*


## 3: Causal paths are not spatially connected 



Say $A$ causes $B$ --- does that mean that there is a spatiotemporally continuous sequence of causal intermediates? 
		

* Person $A$ is planning some action $Y$
* Person $B$ sets out to stop them
* Person $X$ intervenes and prevents $B$ from stopping person $A$
		
In this case Person $A$ may complete their action, producing $Y$, without any knowledge that $B$ and $X$ even exist; in particular $X$ need not be anywhere close to the action. 

But still, $X$ caused $Y$ 

*What implications of non-connectedness?*



## 4: Causes are not rival 

The counterfactual model focuses on contribution. It can be used to assess  attribution in a very conditional sense (i.e. given $X=Y=1$ did $X$ cause $Y$) but not in an absolute sense ("the" cause). 

* Focus is on  **non-rival** contributions. Not: what caused $Y$ but **what is the effect of $X$**? 
* At most it provides a conditional account of what caused $Y$---whether a particular thing caused $Y$, given other things.

Consider at outcome $Y$ that might depend on two causes $X_1$ and $X_2$:
$$Y(0,0) = 0$$
$$Y(1,0) = 0$$
$$Y(0,1) = 0$$
$$Y(1,1) = 1$$

What caused $Y$? Which cause was most important?


## 4: Causes are not rival 

The counterfactual model focuses on contribution. It can be used to assess  attribution in a very conditional sense (i.e. given $X=Y=1$ did $X$ cause $Y$) but not in an absolute sense ("the" cause). 

* Focus is on  **non-rival** contributions. Not: what caused $Y$ but **what is the effect of $X$**? 
* At most it provides a conditional account of what caused $Y$---whether a particular thing caused $Y$, given other things.

Consider at outcome $Y$ that might depend on two causes $X_1$ and $X_2$:
$$Y(0,0) = 0$$
$$Y(1,0) = 1$$
$$Y(0,1) = 1$$
$$Y(1,1) = 1$$

What caused $Y$? Which cause was most important?


## 4: Causes are not rival 

The counterfactual model focuses on contribution. It can be used to assess  attribution in a very conditional sense (i.e. given $X=Y=1$ did $X$ cause $Y$) but not in an absolute sense ("the" cause). 

* This is problem for research programs that define "explanation" in terms of figuring out *the* things that cause $Y$
* Real difficulties conceptualizing what it means to say one cause is more important than another cause. What does that mean?

<!-- ## 4: Causes are not rival  -->

<!-- The counterfactual model focuses on contribution, not attribution, except in a very conditional sense.  -->


<!-- * *Erdogan's increasing authoritarianism was the most important reason for the attempted coup* -->
<!--     * More important than Turkey's history of coups? -->
<!--     * What does that mean? -->


<!-- ## The difference between an *actual* cause a *counterfactual* cause -->

<!-- * Susie and Billy throw rocks at a bottle -->
<!-- * Both are great aims and, if they were the only ones throwing, would certainly hit the bottl.e -->
<!-- * Susie is a faster throw however and her rock hits the bottle first. -->
<!-- * Billy's throw is a little slower and flys past the now broken bottle. -->

<!-- **Question**: Which stone broke the bottle? -->


<!-- ## The difference between an *actual* cause and a *counterfactual* cause -->

<!-- * Susie and Billy throw rocks at a bottle -->
<!-- * Both are great aims and, if they were the only ones throwing, would certainly hit the bottl.e -->
<!-- * Susie is a faster throw however and her rock hits the bottle first. -->
<!-- * Billy's throw is a little slower and flys past the now broken bottle. -->

<!-- **Question**: From a counterfactual perspective *neither* broke the bottle since the bottle would have broken in the absence of any single throw. Yet it seems obvious that Susie's throw actually broke the bottle. (To think about: what does "actually" caused actually mean?)  -->



## 5: No causation without manipulation

* Some seemingly causal claims not admissible. 
* To get the definition off the ground, **manipulation must be imaginable** (whether practical or not)
* This renders thinking about effects of race and gender difficult
* What does it mean to say that Aunt Pat voted for Brexit because she is old?


## 5: No causation without manipulation

* Some seemingly causal claims not admissible. 
* To get the definition off the ground, **manipulation must be imaginable** (whether practical or not)
* This renders thinking about effects of race and gender difficult
* **Compare**: What does it mean to say that Southern counties voted for Brexit because they have many old people?


<!-- ## Causal claims: Causal claims are everywhere -->

<!-- Which of these statements involve causal claims: -->

<!-- * Jack exploited Jill -->
<!-- * It's Jill's fault that bucket fell -->
<!-- * Jack is the most obstructionist member of Congress -->
<!-- * Melania Trump stole from Michelle Obama's speech -->

<!-- So: -->

<!-- * Policymakers and activists need causal claims -->



## Exercise your potential outcomes 1

Consider the following potential outcomes table:

\begin{table} \centering
\begin{tabular}{c|c|c|c}
Unit	&Y(0)	&Y(1)	&$\tau_i$ \\ \hline
1	& 4	& 3	\\
2	& 2	& 3	\\
3	& 1	& 3	\\
4	& 1	& 3	\\
5	& 2	& 3	
\end{tabular} 
\end{table}

\color{red}\textbf{Questions for us:} What are the unit level treatment effects? What is the average treatment effect?	


## Exercise your potential outcomes 2
Consider the following potential outcomes table:
\begin{table} \centering

	\begin{tabular}{c|c|c}
		In treatment?	&Y(0)	&Y(1)  \\ \hline
		Yes	&	& 2	\\
		No	& 3	&	\\
		No	& 1	&	\\
		Yes	&	& 3	\\
		Yes	&	& 3	\\
		No	& 2	&	
	\end{tabular} 
\end{table}

\color{red}\textbf{Questions for us: } Fill in the blanks.
\begin{itemize}
	\item Assuming a constant treatment effect of $+1$ 
	\item Assuming a constant treatment effect of $-1$ 
	\item Assuming an \textit{average} treatment effect of $0$
\end{itemize}
\color{red} What is the actual treatment effect?


## Takeaway on Causal Claims

* \color{red}Takeaway\color{black}: A causal claim is always partly a claim about what **did not happen**

